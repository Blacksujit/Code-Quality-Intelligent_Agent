# ğŸš€ Code Quality Intelligence Agent (MVP)

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![AI](https://img.shields.io/badge/AI-Powered-FF6B6B?style=for-the-badge&logo=openai&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**An AI-powered agent that analyzes multi-language codebases, identifies quality issues, and produces actionable reports with explanations, fix suggestions, prioritization, hotspots, and interactive Q&A over the codebase.**

[ğŸ¯ Features](#-features) â€¢ [âš¡ Quick Start](#-quick-start) â€¢ [ğŸ”§ Setup](#-setup) â€¢ [ğŸ“– Usage](#-usage) â€¢ [ğŸ¤– AI Integration](#-ai-integration) â€¢ [ğŸš€ Deployment](#-deployment) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸ“‹ Table of Contents

- [ğŸ“š Architecture](#-architecture)
- [ğŸ¯ Features](#-features)
- [âš¡ Quick Start](#-quick-start)
- [ğŸ¥ Explanation Video](#-explanation-video)
- [ğŸ”§ Setup](#-setup)
- [ğŸ“– Usage](#-usage)
- [ğŸ¤– AI Integration](#-ai-integration)
- [ğŸ¨ Web Interface](#-web-interface)
- [ğŸ”Œ CLI Commands](#-cli-commands)
- [ğŸ“Š Visualizations](#-visualizations)
- [ğŸš€ Deployment](#-deployment)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“„ License](#-license)

---

---

## ğŸ“š Architecture

### ğŸ—ï¸ **System Architecture**

```mermaid
graph TB
    A[User Interface] --> B[CLI/Web]
    B --> C[Analysis Engine]
    C --> D[Language Analyzers]
    C --> E[Quality Metrics]
    C --> F[Dependency Graph]
    C --> G[AI Integration]
    
    D --> H[Python Analyzers]
    D --> I[JS/TS Analyzers]
    
    E --> J[Hotspot Detection]
    E --> K[Issue Prioritization]
    
    F --> L[Network Analysis]
    F --> M[Hierarchy Building]
    
    G --> N[DeepSeek API]
    G --> O[Local LLM]
    G --> P[Hugging Face]
    
    C --> Q[Visualization Engine]
    Q --> R[Plotly Charts]
    Q --> S[Interactive Graphs]
    
    C --> T[Report Generation]
    T --> U[Markdown]
    T --> V[SARIF]
    T --> W[CSV]
```

## ğŸ¯ Features

### ğŸ” **Multi-Language Analysis**
- **Python**: Ruff, Bandit, Radon analysis
- **JavaScript/TypeScript**: ESLint with security plugins
- **Smart Detection**: Automatic language detection and appropriate tooling

### ğŸ¤– **AI-Powered Intelligence**
- **DeepSeek Integration**: Remote AI for advanced analysis
- **Local LLM Fallback**: Offline AI using Hugging Face models
- **Smart Severity Scoring**: AI-enhanced issue prioritization
- **Conversational Q&A**: Natural language codebase exploration

### ğŸ“Š **Advanced Visualizations**
- **Interactive Charts**: Plotly-powered dashboards
- **Dependency Graphs**: Network analysis and hierarchy visualization
- **Hotspot Analysis**: Code complexity and churn heatmaps
- **Trend Analysis**: Quality metrics over time

### âš¡ **Performance Optimized**
- **Incremental Caching**: Smart file change detection
- **Parallel Processing**: Multi-threaded analysis
- **Sampling Tiers**: Efficient large repository handling
- **Fast Mode**: Optimized for 1000+ file repositories

### ğŸ› ï¸ **Developer Experience**
- **Modern Web UI**: Streamlit with glassmorphism design
- **CLI Interface**: Command-line tool for CI/CD integration
- **Autofix Capabilities**: Safe automated code improvements
- **Export Options**: Markdown, SARIF, CSV reports

---

## âš¡ Quick Start

### ğŸ **Prerequisites**
- Python 3.11 or higher
- Git (for repository analysis)
- 4GB+ RAM (for AI features)

### ğŸ“¦ **Installation**

```bash
# Clone the repository
git clone https://github.com/Blacksujit/Code-Quality-Intelligent_Agent
cd code-quality-agent

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install the package
python -m pip install -e .

# Install optional AI dependencies
python -m pip install transformers torch
```

### ğŸš€ **Run Web Interface**

```bash
# Launch the modern web interface
streamlit run src/cq_agent/web/app.py

# Or use the demo script
python demo_ui.py
```

**ğŸŒ Open your browser to:** `http://localhost:8501`

---

## ğŸ”§ Setup

### ğŸ“ **Project Structure**

```
code-quality-agent/
â”œâ”€â”€ ğŸ“ src/cq_agent/
â”‚   â”œâ”€â”€ ğŸ“ analyzers/          # Code analysis engines
â”‚   â”œâ”€â”€ ğŸ“ ai/                 # AI integration modules
â”‚   â”œâ”€â”€ ğŸ“ cli/                # Command-line interface
â”‚   â”œâ”€â”€ ğŸ“ graph/              # Dependency analysis
â”‚   â”œâ”€â”€ ğŸ“ metrics/            # Quality metrics
â”‚   â”œâ”€â”€ ğŸ“ qa/                 # Q&A and search
â”‚   â”œâ”€â”€ ğŸ“ reporting/          # Report generation
â”‚   â”œâ”€â”€ ğŸ“ visualizations/     # Chart and graph creation
â”‚   â””â”€â”€ ğŸ“ web/                # Streamlit web interface
â”œâ”€â”€ ğŸ“ assignment-docs/        # Project documentation
â”œâ”€â”€ ğŸ“„ pyproject.toml          # Dependencies and metadata
â””â”€â”€ ğŸ“„ README.md              # This file
```

### ğŸ”‘ **Environment Configuration**

Create a `.env` file in the project root:

```env
# AI Configuration (Optional)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
HF_TOKEN=your_huggingface_token_here
HUGGINGFACEHUB_API_TOKEN=your_hf_inference_token_here

# Performance Settings
MAX_FILES=1000
WORKER_THREADS=4
```

### ğŸ“¦ **Dependencies**

#### **Core Dependencies**
```bash
# Essential packages (auto-installed)
pip install streamlit pandas plotly numpy
pip install gitpython pathlib typing-extensions
```

#### **AI Dependencies (Optional)**
```bash
# For local LLM support
pip install transformers torch

# For enhanced semantic search
pip install faiss-cpu sentence-transformers

# For advanced AI agents
pip install langchain langchain-community
```

#### **Analysis Tools**
```bash
# Python analysis (auto-installed)
pip install ruff bandit radon

# JavaScript/TypeScript analysis (optional)
npm install -g eslint
```

---

## ğŸ¥ Explanation Video

### ğŸ“º **Project Demo & Walkthrough**

<div align="center">

[![Code Quality Intelligence Agent Demo](https://img.shields.io/badge/ğŸ¥_Watch_Demo-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtu.be/pa7KMkA-bxI)

**ğŸ“¹ Complete Project Explanation & Demo Video**

</div>


#### **ğŸ¬ Video Quality & Features:**

- âœ… **HD Quality**: 1080p recording for clear visibility
- âœ… **Screen Recording**: Full desktop capture with annotations
- âœ… **Audio Commentary**: Clear explanations throughout
- âœ… **Code Highlighting**: Syntax highlighting for better understanding
- âœ… **Interactive Elements**: Live demonstrations of all features
- âœ… **Multiple Scenarios**: Different repository types analyzed

#### **ğŸ“± Access Options:**

- **ğŸ¥ YouTube**: [Watch on YouTube](coming soon ...)
- **ğŸ“º Direct Link**: [Direct Video Access](scoming soon ...)
- **ğŸ“± Mobile Friendly**: Optimized for mobile viewing
- **â¯ï¸ Playback Controls**: Pause, rewind, and speed control

#### **ğŸ’¡ Video Highlights:**

> **"See how the Code Quality Intelligence Agent transforms complex codebases into actionable insights with AI-powered analysis, interactive visualizations, and intelligent recommendations."**

- ğŸ§‘â€ğŸ’» **CLI**: Watch live CLI demo 
- ğŸ” **Real-time Analysis**: Watch live code analysis in action
- ğŸ“Š **Interactive Dashboards**: Explore dynamic visualizations
- ğŸ¤– **AI Conversations**: Experience natural language Q&A
- ğŸš€ **One-Click Deployment**: See effortless setup process
- ğŸ“ˆ **Comprehensive Reports**: Generate detailed quality reports

---

## ğŸ“– Usage

### ğŸ¨ **Web Interface**

The Streamlit web interface provides a modern, interactive experience:

#### **ğŸ”§ Analysis Configuration**
- **Repository Path**: Select or enter your codebase location
- **File Limits**: Configure analysis scope (default: 1000 files)
- **Fast Mode**: Enable for large repositories (1000+ files)
- **AI Backend**: Choose between DeepSeek, Local LLM, or Disabled

#### **ğŸ“Š Dashboard Tabs**
1. **ğŸ“ˆ Overview**: Quality metrics and summary cards
2. **ğŸ” Issues**: Filterable issue list with AI enhancements
3. **ğŸ“ File Details**: Per-file analysis and code context
4. **ğŸ”§ Autofix**: Safe automated code improvements
5. **ğŸ“¤ Export**: Download reports in multiple formats
6. **ğŸŒ Dependencies**: Interactive dependency graphs
7. **ğŸ”¥ Hotspots**: Code complexity and churn analysis
8. **ğŸ“ˆ Trends**: Quality metrics over time
9. **ğŸ¤– AI Q&A**: Conversational codebase exploration


## ğŸ”Œ CLI Commands

#### **ğŸ“Š Analysis Commands**

```bash
# Basic analysis
cq-agent analyze .

# Generate reports
cq-agent analyze . --md report.md --sarif security.sarif

# Preview and apply autofixes
cq-agent analyze . --autofix-dry-run
cq-agent analyze . --autofix

# AI-enhanced analysis
cq-agent analyze . --deepseek
```

#### **ğŸ’¬ Q&A Commands**

```bash
# Interactive Q&A (extractive mode)
cq-agent qa .

# DeepSeek AI Q&A
cq-agent qa . --deepseek

# Local LLM Q&A
cq-agent qa . --local-llm

# Agentic Q&A with Hugging Face
cq-agent qa . --agent --agent-backend hf --agent-model "HuggingFaceH4/zephyr-7b-beta"
```

----

### ğŸ“‹ **Command Reference**

| Command | Description | Example |
|---------|-------------|---------|
| `analyze <path>` | Analyze code repository | `cq-agent analyze .` |
| `--md <file>` | Generate Markdown report | `--md report.md` |
| `--sarif <file>` | Generate SARIF report | `--sarif security.sarif` |
| `--autofix-dry-run` | Preview safe fixes | `--autofix-dry-run` |
| `--autofix` | Apply safe fixes | `--autofix` |
| `--incremental` | Use incremental cache | `--incremental` |
| `--no-incremental` | Disable cache | `--no-incremental` |
| `--deepseek` | Enable DeepSeek AI | `--deepseek` |
| `qa <path>` | Interactive Q&A | `cq-agent qa .` |
| `--local-llm` | Use local LLM | `--local-llm` |
| `--agent` | Use agentic Q&A | `--agent` |
| `--agent-backend <type>` | AI backend type | `--agent-backend hf` |
| `--agent-model <name>` | AI model name | `--agent-model llama3.1` |

### ğŸ”§ **Performance Flags**

```bash
# Fast mode for large repositories
cq-agent analyze . --max-files 1000

# Incremental analysis (default)
cq-agent analyze . --incremental

# Fresh analysis
cq-agent analyze . --no-incremental

# Parallel processing
cq-agent analyze . --workers 8
```
---
---

## ğŸ¤– AI Integration

### ğŸŒ **DeepSeek (Remote AI)**

**Best for**: Production use, most capable analysis

```bash
# Set API key
export DEEPSEEK_API_KEY="your_key_here"

# Use in web interface or CLI
cq-agent analyze . --deepseek
cq-agent qa . --deepseek
```

**Features**:
- âœ… Advanced code understanding
- âœ… Smart severity re-ranking
- âœ… Comprehensive Q&A responses
- âŒ Requires API key and internet

### ğŸ  **Local LLM (Offline AI)**

**Best for**: Development, privacy, offline work

```bash
# Install dependencies
pip install transformers torch

# Use in web interface (select "Local LLM (Fast)")
# Or CLI
cq-agent qa . --local-llm --local-model "microsoft/DialoGPT-small"
```

**Features**:
- âœ… No API keys required
- âœ… Works offline
- âœ… Fast for development
- âœ… Privacy-focused
- âŒ Limited model capabilities

### ğŸ”„ **Hugging Face Integration**

**Best for**: Custom models, inference endpoints

```bash
# Router (OpenAI-compatible)
export HF_TOKEN="hf_..."
cq-agent qa . --agent --agent-backend hf --agent-model "HuggingFaceH4/zephyr-7b-beta:featherless-ai"

# Inference API
export HUGGINGFACEHUB_API_TOKEN="hf_..."
cq-agent qa . --agent --agent-backend hf --agent-model "HuggingFaceH4/zephyr-7b-beta"
```

### ğŸ¯ **AI Backend Selection Guide**

| Backend | Speed | Capability | Privacy | Cost | Best For |
|---------|-------|------------|---------|------|----------|
| **DeepSeek** | â­â­â­ | â­â­â­â­â­ | â­â­ | ğŸ’°ğŸ’° | Production |
| **Local LLM** | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | ğŸ’° | Development |
| **HF Router** | â­â­â­ | â­â­â­â­ | â­â­â­ | ğŸ’°ğŸ’° | Custom models |
| **Extractive** | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ | ğŸ’° | No AI needed |

---

## ğŸ¨ Web Interface

### ğŸ­ **Modern Design Features**

- **ğŸŒŠ Glassmorphism Theme**: Modern, translucent UI elements
- **ğŸ“± Responsive Layout**: Works on desktop, tablet, and mobile
- **ğŸ¨ Interactive Charts**: Plotly-powered visualizations
- **âš¡ Real-time Updates**: Live progress bars and status updates
- **ğŸ¯ Smart Filtering**: Advanced search and filter capabilities

### ğŸ“Š **Visualization Types**

#### **ğŸ“ˆ Overview Dashboard**
- Quality score gauge
- Severity distribution charts
- Language breakdown
- File count metrics

#### **ğŸŒ Dependency Analysis**
- Interactive network graphs
- Hierarchical sunburst charts
- Dependency heatmaps
- Centrality analysis

#### **ğŸ”¥ Hotspot Analysis**
- Code complexity treemaps
- Churn vs. complexity scatter plots
- Language comparison radar charts
- Directory-level heatmaps

#### **ğŸ“ˆ Trend Analysis**
- Quality metrics over time
- Commit activity heatmaps
- Lines changed charts
- Issue resolution trends

---

---

## ğŸ“Š Visualizations

### ğŸ¨ **Chart Types**

#### **ğŸ“Š Bar Charts**
- Severity distribution
- Language breakdown
- Issue categories
- File complexity

#### **ğŸŒ Network Graphs**
- Dependency relationships
- File connections
- Module interactions
- Import/export flows

#### **ğŸ”¥ Heatmaps**
- Code complexity by directory
- Issue density by file
- Churn patterns
- Language comparison

#### **ğŸ“ˆ Time Series**
- Quality trends
- Commit activity
- Issue resolution
- Code growth

#### **ğŸ¯ Specialized Charts**
- **Sunburst**: Hierarchical dependency structure
- **Treemap**: File size and complexity
- **Radar**: Multi-dimensional language comparison
- **Scatter**: Complexity vs. churn analysis

---

## ğŸš€ Deployment

### ğŸ³ **Docker Deployment**

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . .
RUN pip install -e .

EXPOSE 8501
CMD ["streamlit", "run", "src/cq_agent/web/app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```bash
# Build and run
docker build -t code-quality-agent .
docker run -p 8501:8501 code-quality-agent
```

### â˜ï¸ **Cloud Deployment**

#### **ğŸŒ Streamlit Cloud**
```yaml
# .streamlit/secrets.toml
DEEPSEEK_API_KEY = "your_key_here"
HF_TOKEN = "your_hf_token_here"
```

#### **ğŸª° Fly.io**
```bash
# fly.toml (already included)
fly launch
fly deploy
```

#### **ğŸ³ Railway**
```bash
# railway.json
{
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "streamlit run src/cq_agent/web/app.py --server.port=$PORT --server.address=0.0.0.0"
  }
}
```

### ğŸ”§ **Environment Variables**

```bash
# Production environment
export DEEPSEEK_API_KEY="your_production_key"
export HF_TOKEN="your_hf_token"
export MAX_FILES="2000"
export WORKER_THREADS="8"
export STREAMLIT_SERVER_PORT="8501"
export STREAMLIT_SERVER_ADDRESS="0.0.0.0"
```

### ğŸš€ **Quick Deployment Commands**

```bash
# Make deployment script executable (Linux/Mac)
chmod +x deploy.sh

# Deploy to different platforms
./deploy.sh streamlit    # Streamlit Cloud (Free)
./deploy.sh railway      # Railway (Free tier)
./deploy.sh render       # Render (Free tier)
./deploy.sh fly          # Fly.io (Free tier)
./deploy.sh local        # Local Docker
```

---

## ğŸ¤ Contributing

### ğŸš€ **Getting Started**

1. **ğŸ´ Fork the repository**
2. **ğŸ“¥ Clone your fork**
   ```bash
   git clone https://github.com/your-username/code-quality-agent.git
   cd code-quality-agent
   ```
3. **ğŸŒ¿ Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
4. **ğŸ”§ Set up development environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -e ".[dev]"
   ```

### ğŸ§ª **Development Setup**

```bash
# Install development dependencies
pip install -e ".[dev,local_llm,ai]"

# Run tests
python -m pytest tests/

# Run linting
ruff check src/
black src/

# Run type checking
mypy src/
```

### ğŸ“ **Contributing Guidelines**

#### **ğŸ¯ Areas for Contribution**
- **ğŸ” New Analyzers**: Add support for more languages
- **ğŸ¤– AI Models**: Integrate additional LLM backends
- **ğŸ“Š Visualizations**: Create new chart types
- **ğŸ”§ CLI Features**: Add new command-line options
- **ğŸ“± UI Improvements**: Enhance the web interface
- **ğŸ“š Documentation**: Improve guides and examples

#### **ğŸ“‹ Pull Request Process**
1. **âœ… Ensure tests pass**
2. **ğŸ“ Update documentation**
3. **ğŸ¨ Follow code style guidelines**
4. **ğŸ“‹ Provide clear description**
5. **ğŸ”— Link related issues**

#### **ğŸ·ï¸ Issue Labels**
- `ğŸ› bug`: Something isn't working
- `âœ¨ enhancement`: New feature or request
- `ğŸ“š documentation`: Documentation improvements
- `ğŸ¨ ui/ux`: User interface improvements
- `ğŸ¤– ai`: AI-related features
- `âš¡ performance`: Performance improvements
- `ğŸ”§ maintenance`: Code maintenance tasks

---

### ğŸ”§ **Core Modules**

| Module | Purpose | Key Components |
|--------|---------|----------------|
| **ğŸ” Analyzers** | Code analysis engines | Python, JS/TS, AST parsing |
| **ğŸ¤– AI** | AI integration | DeepSeek, Local LLM, HF |
| **ğŸŒ Graph** | Dependency analysis | NetworkX, centrality metrics |
| **ğŸ“Š Metrics** | Quality measurement | Hotspots, complexity, churn |
| **ğŸ¨ Visualizations** | Chart generation | Plotly, interactive graphs |
| **ğŸ“ Reporting** | Output generation | Markdown, SARIF, CSV |
| **ğŸ’¬ Q&A** | Code search and query | TF-IDF, semantic search |
| **ğŸ”§ Autofix** | Automated fixes | Safe transformations |

### ğŸ”„ **Data Flow**

1. **ğŸ“ Repository Ingestion**: Load and parse codebase
2. **ğŸ” Analysis**: Run language-specific analyzers
3. **ğŸ“Š Metrics Calculation**: Compute quality metrics
4. **ğŸŒ Graph Building**: Create dependency relationships
5. **ğŸ¤– AI Enhancement**: Apply AI-powered insights
6. **ğŸ¨ Visualization**: Generate interactive charts
7. **ğŸ“ Report Generation**: Create output documents

---

## ğŸ”§ Troubleshooting

### âŒ **Common Issues**

#### **ğŸ Python Version**
```bash
# Ensure Python 3.11+
python --version

# If using older version, upgrade
pyenv install 3.11.0
pyenv local 3.11.0
```

#### **ğŸ“¦ Missing Dependencies**
```bash
# Reinstall package
pip uninstall cq-agent
pip install -e .

# Install optional dependencies
pip install transformers torch
pip install faiss-cpu sentence-transformers
```

#### **ğŸ”‘ API Key Issues**
```bash
# Check environment variables
echo $DEEPSEEK_API_KEY
echo $HF_TOKEN

# Set in .env file
echo "DEEPSEEK_API_KEY=your_key" >> .env
```

#### **ğŸŒ Streamlit Issues**
```bash
# Clear Streamlit cache
streamlit cache clear

# Check port availability
lsof -i :8501

# Use different port
streamlit run src/cq_agent/web/app.py --server.port 8502
```

#### **ğŸ¤– AI Model Issues**
```bash
# Check model availability
python -c "from transformers import pipeline; print('Models available')"

# Clear model cache
rm -rf ~/.cache/huggingface/

# Use smaller model
cq-agent qa . --agent --agent-model "microsoft/DialoGPT-small"
```

### ğŸ†˜ **Getting Help**

- **ğŸ“– Documentation**: Check this README and inline docs
- **ğŸ› Issues**: Search existing GitHub issues
- **ğŸ’¬ Discussions**: Use GitHub Discussions for questions
- **ğŸ“§ Contact**: Create a new issue for bugs or feature requests

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**ğŸš€ Built with â¤ï¸ for the developer community**

â€¢[â­ Star this repo](https://github.com/Blacksujit/Code-Quality-Intelligent_Agent) 

</div>