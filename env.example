# üîê Code Quality Intelligence Agent - Environment Variables Template
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!

# =============================================================================
# ü§ñ AI API Keys (Optional - for enhanced features)
# =============================================================================

# DeepSeek API Key (for AI-powered Q&A and issue enhancement)
# Get your key from: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Hugging Face Token (for local LLM fallback)
# Get your token from: https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Hugging Face Hub API Token (alternative to HF_TOKEN)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACEHUB_API_TOKEN=your_hf_hub_token_here

# OpenAI API Key (if using OpenAI models)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# üöÄ Performance Configuration
# =============================================================================

# Maximum number of files to analyze (0 = no limit)
MAX_FILES=1000

# Number of worker threads for parallel processing
WORKER_THREADS=4

# Cache TTL in seconds (3600 = 1 hour)
CACHE_TTL=3600

# =============================================================================
# üéØ Streamlit Configuration
# =============================================================================

# Streamlit server port
STREAMLIT_SERVER_PORT=8501

# Streamlit server address
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Streamlit theme (light, dark, auto)
STREAMLIT_THEME=auto

# =============================================================================
# ü§ñ AI Model Configuration
# =============================================================================

# Local LLM model for fallback (small, fast models recommended)
LOCAL_MODEL=microsoft/DialoGPT-small

# Hugging Face model for Q&A
HF_MODEL=HuggingFaceH4/zephyr-7b-beta

# =============================================================================
# üîß Development Configuration
# =============================================================================

# Enable debug mode (true/false)
DEBUG=false

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# üóÑÔ∏è Database Configuration (if using external DB)
# =============================================================================

# Database URL (for production deployments)
# DATABASE_URL=postgresql://user:password@localhost:5432/cq_agent

# Redis URL (for caching)
# REDIS_URL=redis://localhost:6379/0

# =============================================================================
# ‚òÅÔ∏è Deployment Configuration
# =============================================================================

# Environment (development, staging, production)
ENVIRONMENT=development

# Application URL (for production)
# APP_URL=https://your-app-name.streamlit.app

# =============================================================================
# üîí Security Configuration
# =============================================================================

# Secret key for session management
SECRET_KEY=your_secret_key_here

# Allowed hosts (comma-separated)
ALLOWED_HOSTS=localhost,127.0.0.1

# =============================================================================
# üìä Analytics and Monitoring (Optional)
# =============================================================================

# Google Analytics ID
# GA_TRACKING_ID=UA-XXXXXXXXX-X

# Sentry DSN for error tracking
# SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id

# =============================================================================
# üéØ Feature Flags
# =============================================================================

# Enable AI features (true/false)
ENABLE_AI=true

# Enable local LLM fallback (true/false)
ENABLE_LOCAL_LLM=true

# Enable incremental caching (true/false)
ENABLE_CACHING=true

# Enable parallel processing (true/false)
ENABLE_PARALLEL=true

# =============================================================================
# üìù Notes
# =============================================================================
# 
# 1. Copy this file to .env: cp .env.example .env
# 2. Fill in your actual API keys and configuration
# 3. Never commit .env to version control
# 4. For production, use environment variables or secure secret management
# 5. All AI features are optional - the app works without API keys
# 6. Start with minimal configuration and add features as needed
#
# =============================================================================
